
\documentclass[letterpaper,11pt]{article}
\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{framed}
\usepackage{tocloft}
\usepackage{bibentry}
\usepackage{amsmath}
\usepackage{scrextend}
\usepackage{listings}
\usepackage{color}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{pgfplots}
% Adjust margins
\usepackage[left=1in,top=0.7in,right=1in,bottom=0.6in]{geometry}

  %THIS PORTION IS FOR ADDING PAGE NUMBER
  \pagestyle{fancy}
  \cfoot{}
  \rfoot{\thepage}
  \renewcommand{\headrulewidth}{0pt}
  %THIS PORTION IS FOR ADDING PAGE NUMBER.


  \urlstyle{same}
  \definecolor{mygrey}{gray}{.85}
  \definecolor{mygreylink}{gray}{.30}
  \textheight=9.0in
  \raggedbottom
  \raggedright
  \setlength{\tabcolsep}{0in}


  %The following part is for inserting codes in LaTeX:
  \definecolor{codegreen}{rgb}{0,0.6,0}
  \definecolor{codegray}{rgb}{0.5,0.5,0.5}
  \definecolor{codepurple}{rgb}{0.58,0,0.82}
  \definecolor{backcolour}{rgb}{0.95,0.95,0.92}

  \lstdefinestyle{mystyle}{
      backgroundcolor=\color{backcolour},
      commentstyle=\color{codegreen},
      keywordstyle=\color{magenta},
      numberstyle=\tiny\color{codegray},
      stringstyle=\color{codepurple},
      basicstyle=\footnotesize,
      breakatwhitespace=false,
      breaklines=true,
      captionpos=b,
      keepspaces=true,
      numbers=left,
      numbersep=5pt,
      showspaces=false,
      showstringspaces=false,
      showtabs=false,
      tabsize=2
  }
  \lstset{style=mystyle}
  %For inserting codes in LaTeX

  \begin{document}

  \begin{center}
  	\textbf{\Huge{Advanced Data Analysis HW3}}
  \end{center}

  \begin{center}
  	\textsl{Ao Liu, al3472}
  \end{center}


  \bigbreak
  \bigbreak
  \bigbreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%   1   %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{addmargin}[-2em]{0em}
\large{\textbf{1. }}\end{addmargin}
\begin{addmargin}[-1.1em]{0em} \textbf{Consider a regression model with $p$ predictors, that is,}\par \end{addmargin}
  $$Y_i = \beta_0+\beta_1 X_{1i}+...+\beta_p X_{pi}+\epsilon_i,i=1,2,...,n$$
\bigbreak

\begin{addmargin}[-1.1em]{0em}
\textbf{(a)}\par\end{addmargin}
\textbf{Show that}\par
$$F=\frac{n-p-1}{p}\frac{R^2}{1-R^2}$$

\begin{addmargin}[-0.5em]{0em}
\textbf{Answer: }\end{addmargin}


%%insert equation with severl lines:
\begin{align}
F &= \frac{SSR/dfR}{SSE/dfE} \nonumber\\
  &= \frac{SSR}{SST-SSR}\times\frac{n-p-1}{p} \nonumber\\
  &= \frac{1}{\frac{SST}{SSR}-1}\times\frac{n-p-1}{p}\nonumber\\
  &= \frac{1}{1/R^2-1}\times\frac{n-p-1}{p}\nonumber\\
  &= \frac{n-p-1}{p}\frac{R^2}{1-R^2}\nonumber
\end{align}


\begin{addmargin}[-1.1em]{0em}
\textbf{(b)}\par\end{addmargin}
  \textbf{If $n$=20, $p$=3, $R^2$ =0.572. Test $H_0$:$\beta_1$ =$\beta_2$ =$\beta_3$ =0 against $H_a$: at least one of them is not zero.}\par
\bigbreak

\begin{addmargin}[-0.5em]{0em}
\textbf{Answer: }\end{addmargin}

\begin{lstlisting}
> n=20
> p=3
> R2=0.572
> F=(n-p-1)/p*R2/(1-R2)
> F
> qf(.95,df1=p,df2=n-p-1)
\end{lstlisting}

\begin{lstlisting}
  7.12772585779782
  3.23887151745358
\end{lstlisting}
Since F statistic is greater than $F(0.95,3,16)$, then we cannot reject the Null Hypothesis that the parameters are all 0.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%   2   %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{addmargin}[-2em]{0em} \large{\textbf{2. }}\end{addmargin}

\begin{addmargin}[-1.1em]{0em} \textbf{Comp-U-Systems, a computer manufacturer, sells and services the Comp-Y-Systems Microcomputers. Let
$x_i$ = the number of microcomputer serviced on the $i$th service call
$y_i$ = the number of minutes required to perform service on the ith service call
the data is in file CompUSys.csv. Suppose the model $y_i$ = $\beta_0$ + $\beta_1x_i$ + $\epsilon_i$, $i$ = 1, 2, . . . , $n$, is used to model the relationship between the number of minutes required to perform a service and the number of microcomputers serviced.
}\par\end{addmargin}

\bigbreak
\begin{addmargin}[-1.1em]{0em}
\textbf{(a)}\par\end{addmargin}
\textbf{Estimate $\beta_0$ and $\beta_1$ using the least square method. Interpret the estimate of $\beta_1$.}\par
\bigbreak
\begin{addmargin}[-0.5em]{0em}
\textbf{Answer: }\end{addmargin}

\begin{lstlisting}
> data = read.csv("CompUSys.csv")
> y = data[,2]
> x = data[,1]
> lm(y~x)
\end{lstlisting}

\begin{lstlisting}
  Call:
  lm(formula = y ~ x)

  Coefficients:
  (Intercept)            x
        11.46        24.60
\end{lstlisting}
By using the least square method, the estimation of $\beta_0$ is 11.46 and the estimation of $\beta_1$ is 24.60.\par
If the number of microcomputer serviced on the $i$th call increases by 1, then the number of minutes required to perform service on $i$th service call will increase by 24.60 on average.
  \bigbreak
  \begin{addmargin}[-1.1em]{0em}
  \textbf{(b)}\par\end{addmargin}
    \textbf{Use a 95\% confidence interval to estimate $\beta_1$. Interpret your result}\par
  \bigbreak
  \begin{addmargin}[-0.5em]{0em}
  \textbf{Answer: }\end{addmargin}

\begin{lstlisting}
> confint(lm(y~x))
\end{lstlisting}

\begin{lstlisting}
2.5 \%	97.5 \%
(Intercept)	3.684472	19.24371
 x	        22.782272	26.42215
\end{lstlisting}

According to the result we got above, the 95\% confidence interval for $\beta_1$ is:
$$(22.7822,26.4221)$$
Which means we are 95\% confident that one unit increase in the number of microcomputer serviced on the $i$th service call will increase the number of minutes required to perform service on the $i$th call by a range from 22.7822 to 26.4221 on average.

  \bigbreak
  \begin{addmargin}[-1.1em]{0em}
  \textbf{(c)}\par\end{addmargin}
    \textbf{Estimate the average time it will take to serve 6 microcomputer using a 95\% confidence interval. Interpret your result.}\par
%http://stackoverflow.com/questions/12732424/get-confidence-interval-for-one-point-on-regression-line-in-r
\begin{addmargin}[-0.5em]{0em}
\textbf{Answer: }\end{addmargin}

\begin{lstlisting}
> predict(lm(y~x),newdata=data.frame(x=6),interval="confidence")
\end{lstlisting}

\begin{lstlisting}
       fit	      lwr	      upr
  1	  159.0773	154.1388	164.0159
\end{lstlisting}

The output shows that a 95\% confidence interval for the average number of minutes required to perform service for 6 microcomputers is $$[154.1388, 164.0159]$$
Interpretation: We are 95\% confident that the average number of minutes it takes to serve 6 microcomputers ranges between 154.1388 and 164.0159.
  \bigbreak
  \begin{addmargin}[-1.1em]{0em}
  \textbf{(d)}\par\end{addmargin}
    \textbf{Compute a 95\% prediction interval for the amount of time it will take to service 6 microcomputers. Interpret your result.
}\par

  \bigbreak
  \begin{addmargin}[-0.5em]{0em}
  \textbf{Answer: }\end{addmargin}
  \begin{lstlisting}
  > predict(lm(y~x),newdata=data.frame(x=6),interval="prediction")
  \end{lstlisting}

\begin{lstlisting}
          fit	      lwr	      upr
  1	  159.0773	147.5279	170.6268
\end{lstlisting}
The output shows that a 95\% prediction interval for the average number of minutes required to perform service for 6 microcomputers is $$[147.5279, 170.6268]$$
Interpretation: We are 95\% confident that the number of minutes it takes to serve 6 microcomputers ranges between 154.1388 and 164.0159.

  \bigbreak
  \begin{addmargin}[-1.1em]{0em}
  \textbf{(e)}\par\end{addmargin}
    \textbf{Use the Bonferroni method and to find a joint confidence intervals for the mean amounts of time it will take to serve 6 and 7 microcomputers.}\par
  \bigbreak
  \begin{addmargin}[-0.5em]{0em}
  \textbf{Answer: }\end{addmargin}
Since there are two intervals in this method, we divide $\alpha$ by 4:
\begin{lstlisting}
  > predict(lm(y~x),newdata=data.frame(x=6),interval="confidence",level=1-0.05/4)
  > predict(lm(y~x),newdata=data.frame(x=7),interval="confidence",level=1-0.05/4)
\end{lstlisting}

\begin{lstlisting}
       fit	     lwr	    upr
  1	159.0773	152.2858	165.8689
       fit	     lwr	    upr
  1	183.6796	174.8148	192.5443
\end{lstlisting}

 The joint confidence intervals for the mean amounts of time it will take to serve 6 microcomputers is [152.285, 165.8689] and [174.8148, 192.5443] for serving 7 microcomputers.

\bigbreak
\begin{addmargin}[-1.1em]{0em}
\textbf{(f)}\par\end{addmargin}
\textbf{Test}\par
$$H_0 : E(Y|X=x)=\beta_0+\beta_1x $$
$$H_a : Not H_0$$
\textbf{Using $\alpha$ = 0.05.}\par

\bigbreak
\begin{addmargin}[-0.5em]{0em}
\textbf{Answer: }\end{addmargin}

\begin{lstlisting}
> reduced = lm(y~x)
> full = lm(y~factor(x))
> anova(reduced,full)
\end{lstlisting}

\begin{lstlisting}
Res.Df RSS	    Df	Sum of Sq	F	        Pr(>F)
9	     191.7017	NA	NA	      NA	      NA
4	     100.0000	5	  91.70166	0.7336133	0.6353456
\end{lstlisting}
Since the p-value is 0.6353456, we cannot reject the Null Hypothesis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%   3   %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \bigbreak
  \begin{addmargin}[-2em]{0em} \large{\textbf{3. }}\end{addmargin}

  \begin{addmargin}[-1.1em]{0em} \textbf{International Oil Inc. Is attempting to a develop a reasonably priced minimum unleaded gasoline that will deliver higher gasoline mileage than can be achieved by its current premium unleaded gaso- lines. As part of its development process, International Oil Inc. wishes to study the effect of one qualitative variable, x1, premium gasoline un- leaded type (A, B, C) and one quantitative variable x2 amount of gaso- line additive VST (0, 1, 2, 3 units) on the gasoline mileage y obtained by an automobile called Encore. For testing purposes a sample of 22 Encores is randomly selected and driven under normal driving condi- tions. The combination of x1 and x2 used in the experiment along with the corresponding values of y are in file mileage.csv. Define μ[A,x], μ[B,x] and μ[C,x] to be the mean unleaded gasoline mileage by Encore when using AST amount x and premium unleaded gasoline types A, B and C, respectively. Consider the model
}\par\end{addmargin}


$$Y_i =\beta_0 +\beta_1D_{1i} +\beta_2D_{2i} +\beta_3x_2 + \epsilon_i$$

\begin{addmargin}[-1.1em]{0em} \textbf{
where$D_{1i}$ =1 gas type is Band 0 other wise and $D_{2i}$ =1 is gas type is
C and 0 otherwise.}\par\end{addmargin}


    \bigbreak
    \begin{addmargin}[-1.1em]{0em}
    \textbf{(a)}\par\end{addmargin}
      \textbf{Estimate the $beta_{is}$ and interpret your result (see note for how to fit this model )}\par
    \bigbreak

    \begin{addmargin}[-0.5em]{0em}
    \textbf{Answer:}\end{addmargin}

\begin{lstlisting}
> data = read.csv("mileage.csv")
> y = data[,1]
> x1 = data[,2]
> x2 = data[,3]
> lm(y~factor(x1)+x2)
> summary(lm(y~factor(x1)+x2))
\end{lstlisting}

\begin{lstlisting}
  Call:
  lm(formula = y ~ factor(x1) + x2)

  Residuals:
      Min      1Q  Median      3Q     Max
  -4.6171 -1.6321  0.5508  1.3756  4.0021

  Coefficients:
              Estimate Std. Error t value Pr(>|t|)
  (Intercept)  32.0171     1.0005  32.002   <2e-16 ***
  factor(x1)B   1.5218     1.2650   1.203    0.245
  factor(x1)C   0.5252     1.6194   0.324    0.749
  x2           -0.4192     0.6042  -0.694    0.497
  ---
  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

  Residual standard error: 2.532 on 18 degrees of freedom
  Multiple R-squared:  0.09453,	Adjusted R-squared:  -0.05638
  F-statistic: 0.6264 on 3 and 18 DF,  p-value: 0.6072
\end{lstlisting}
The estimation for $\beta_0$ is 32.0171, meaning that when the two factors have no effect, the mileage on average is 32.0171;\par
The estimation for $\beta_1$ is 1.5218, meaning that when VST amount is the same, choosing type B will have 1.5218 more milage than choosing type A on average;\par
The estimation for $\beta_2$ is 0.5252, meaning that when VST amount is the same, choosing type C will have 0.5252 more milage than chooSing type A on average;\par
The estimation for $\beta_3$ is -0.4192, meaning that when the type is the same, increasing 1 unit of VST will cause 0.4192 less milage on average.

\bigbreak
\begin{addmargin}[-1.1em]{0em}
\textbf{(b)}\par\end{addmargin}
\textbf{Test $H_0$ :$\beta_1$ =$\beta_2$ =0 against $H_a$: Not $H_0$ using $\alpha$ = 0.05.}\par
\bigbreak
\begin{addmargin}[-0.5em]{0em}
\textbf{Answer: }\end{addmargin}

According to the result in (a), the F-statistic we got is 0.6264 on 3 and 18 DF, and p-value is 0.6072. Since p-value is greater than 0.05, we cannot reject the Null Hypothesis.
\bigbreak

\end{document}

%Insert pics:
%%%%%%%%%%%%%
%\begin{center}
  %\makebox[\linewidth]{\includegraphics[width=\textwidth]{4640HW6.jpg}}
%\end{center}

%insert a complicated tab...
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{center}
%\begin{tabular}{ p{12cm}p{1cm}p{1cm}p{1cm}  }
%& \multicolumn{3}{c}{Posterior Quantiles} \\
%\centering{Quantity of Interest} & 25\% & 50\% & 75\% \\
%\hline
%geometric mean for Blue Earth (no basement), exp($\beta_2)$ &4.1& 5.0& 6.5\\
%geometric mean for Blue Earth County (basement), exp($\beta_1+\beta_2)$ &6.1 &7.1 &8.2\\
%geometric mean for Clay County (no basement), exp($\beta_3)$& 3.8& 4.7 &5.8\\
%geometric mean for Clay County (basement), exp($\beta_1+\beta_3)$ &5.6& 6.5& 7.6\\
%geometric mean for Goodhue County (no basement), exp($\beta_4)$ & 3.9 &4.9& 6.2\\
%geometric mean for Goodhue County (basement), exp($\beta_1+\beta_4)$ &5.8& 6.8& 7.9\\
%factor for basement vs. no basement, exp($\beta_1$)&1.1& 1.4 &1.7\\
%geometric sd of predictions, exp($\sigma$)&2.1 &2.2& 2.4\\
%\end{tabular}
%\end{center}

%%%insert code snippets:
%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{lstlisting}
%INSERT CODE HERE
%\end{lstlisting}

%%insert equation with severl lines:
%\begin{align}
%LEFT &= RIGHT1 \nonumber\\
%     &= RIGHT2 \nonumber\\
%     &= RIGHT3 \nonumber
%\end{align}


%ssh-add ~/.ssh/id_rsa
